{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pa49bUnKyRgF"
   },
   "source": [
    "# Depth series forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XVhK72Pu1cJL"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:26:52.784670Z",
     "iopub.status.busy": "2023-07-27T04:26:52.784234Z",
     "iopub.status.idle": "2023-07-27T04:26:55.568564Z",
     "shell.execute_reply": "2023-07-27T04:26:55.567878Z"
    },
    "id": "7rZnJaGTWQw0"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import json\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import IPython\n",
    "from IPython.display import Image, display\n",
    "from IPython.lib.display import Audio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "import keras\n",
    "from keras import initializers\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.utils import shuffle\n",
    "mpl.rcParams['figure.figsize'] = (8, 6)\n",
    "mpl.rcParams['axes.grid'] = False\n",
    "keras.utils.set_random_seed(100000)\n",
    "tf.config.experimental.enable_op_determinism()\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from scipy.interpolate import interp1d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TokBlnUhWFw9"
   },
   "source": [
    "##  The multi-modal well logs dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 224
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:26:55.573300Z",
     "iopub.status.busy": "2023-07-27T04:26:55.572611Z",
     "iopub.status.idle": "2023-07-27T04:26:56.097355Z",
     "shell.execute_reply": "2023-07-27T04:26:56.096684Z"
    },
    "id": "xyv_i85IWInT",
    "outputId": "9759c1b4-00bb-41c2-acb5-a8f523092699",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "wells = pd.read_excel('wells 1-4.xlsx')\n",
    "well_5 = pd.read_csv(\"well 5.csv\")[['Depth', 'CGR', 'SGR', 'Facies']]\n",
    "print(well_5.shape)\n",
    "well_5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EdVeEKS6dcMo",
    "outputId": "cce08d71-d4e9-4d72-cdd7-43d8dfa60ad1"
   },
   "outputs": [],
   "source": [
    "well_5.Facies.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 522
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:26:56.977105Z",
     "iopub.status.busy": "2023-07-27T04:26:56.976726Z",
     "iopub.status.idle": "2023-07-27T04:26:59.434254Z",
     "shell.execute_reply": "2023-07-27T04:26:59.433627Z"
    },
    "id": "Vg5XIc5tfNlG",
    "outputId": "9b0af525-d01c-43c4-e42d-1c7c08713ab2"
   },
   "outputs": [],
   "source": [
    "plot_cols = ['CGR', 'SGR', 'Facies']\n",
    "plot_features = well_5[plot_cols]\n",
    "_ = plot_features.plot(subplots=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 175
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:26:59.438905Z",
     "iopub.status.busy": "2023-07-27T04:26:59.438231Z",
     "iopub.status.idle": "2023-07-27T04:26:59.507537Z",
     "shell.execute_reply": "2023-07-27T04:26:59.506919Z"
    },
    "id": "h510pgKVrrai",
    "outputId": "4d7d8931-a57d-4d95-db7e-d4ced48bf0c3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "well_5.describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXWLG0_WBhZS"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_1 = wells[wells['Well Name']==1][['Depth', 'CGR', 'SGR', 'Facies']]\n",
    "well_2 = wells[wells['Well Name']==2][['Depth', 'CGR', 'SGR', 'Facies']]\n",
    "well_3 = wells[wells['Well Name']==3][['Depth', 'CGR', 'SGR', 'Facies']]\n",
    "well_4 = wells[wells['Well Name']==4][['Depth', 'CGR', 'SGR', 'Facies']]\n",
    "\n",
    "def preprocess_well(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    for col in ['CGR', 'SGR']:\n",
    "        df[col] = np.log1p(df[col].clip(lower=0))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    df[['CGR', 'SGR']] = scaler.fit_transform(df[['CGR', 'SGR']])\n",
    "    \n",
    "    df['TVD_increment'] = df['Depth'].diff().fillna(0)  \n",
    "    \n",
    "    df['CGR_depth_norm'] = df['CGR'] / (df['Depth'] + 1e-5)\n",
    "    df['SGR_depth_norm'] = df['SGR'] / (df['Depth'] + 1e-5)\n",
    "    \n",
    "    df['dCGR_dDepth'] = df['CGR'].diff().fillna(0) / df['TVD_increment'].replace(0, np.nan)\n",
    "    df['dSGR_dDepth'] = df['SGR'].diff().fillna(0) / df['TVD_increment'].replace(0, np.nan)\n",
    "    df[['dCGR_dDepth', 'dSGR_dDepth']] = df[['dCGR_dDepth', 'dSGR_dDepth']].fillna(0)\n",
    "    \n",
    "    window = 5\n",
    "    df['CGR_moving_avg'] = df['CGR'].rolling(window=window, min_periods=1).mean()\n",
    "    df['CGR_moving_std'] = df['CGR'].rolling(window=window, min_periods=1).std().fillna(0)\n",
    "    df['SGR_moving_avg'] = df['SGR'].rolling(window=window, min_periods=1).mean()\n",
    "    df['SGR_moving_std'] = df['SGR'].rolling(window=window, min_periods=1).std().fillna(0)\n",
    "    \n",
    "    for col in ['CGR', 'SGR']:\n",
    "        mask = df[col].isnull() | (np.abs(df[col] - df[col].median()) > 3 * df[col].std())\n",
    "        if mask.any():\n",
    "            interp_func = interp1d(df.loc[~mask, 'Depth'], df.loc[~mask, col], kind='linear', fill_value='extrapolate')\n",
    "            df.loc[mask, col] = interp_func(df.loc[mask, 'Depth'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "well_1_pp = preprocess_well(well_1)\n",
    "well_2_pp = preprocess_well(well_2)\n",
    "well_3_pp = preprocess_well(well_3)\n",
    "well_4_pp = preprocess_well(well_4)\n",
    "well_5_pp = preprocess_well(well_5)\n",
    "\n",
    "def align_wells(reference_df, wells_list):\n",
    "    aligned_wells = []\n",
    "    ref_depths = reference_df['Depth'].values\n",
    "    for df in wells_list:\n",
    "        interp_df = pd.DataFrame({'Depth': ref_depths})\n",
    "        for col in df.columns:\n",
    "            if col != 'Depth' and col != 'Facies':\n",
    "                interp_func = interp1d(df['Depth'], df[col], kind='linear', bounds_error=False, fill_value='extrapolate')\n",
    "                interp_df[col] = interp_func(ref_depths)\n",
    "        if 'Facies' in df.columns:\n",
    "            interp_df['Facies'] = reference_df['Facies'].values\n",
    "        aligned_wells.append(interp_df)\n",
    "    return aligned_wells\n",
    "\n",
    "aligned_wells = align_wells(well_5_pp, [well_1_pp, well_2_pp, well_3_pp, well_4_pp])\n",
    "\n",
    "merged_data = well_5_pp.copy()\n",
    "for i, aw in enumerate(aligned_wells, start=1):\n",
    "    suffix = f'_{i}'\n",
    "    for col in aw.columns:\n",
    "        if col not in ['Depth', 'Facies']:\n",
    "            merged_data[col + suffix] = aw[col].values\n",
    "\n",
    "print(merged_data.shape)\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw data visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}\n",
    "with open('Formation.csv', 'r') as file:\n",
    "    next(file) \n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]\n",
    "formations_dict\n",
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)\n",
    "lithology_numbers = {\n",
    "                     1: {'lith':'argiLs', 'lith_num':1, 'hatch':'...', 'color':'#0000FF'},\n",
    "                     2: {'lith':'Sh', 'lith_num':2, 'hatch':'--', 'color':'#565051'},\n",
    "                     3: {'lith':'chkLs', 'lith_num':3, 'hatch':'//', 'color':'#33caff'},\n",
    "                     4: {'lith':'Ls', 'lith_num':4, 'hatch':'o', 'color':'#00FFFF'},\n",
    "                    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 1]\n",
    "x = [1, 1]\n",
    "fig, axes = plt.subplots(ncols=1,nrows=4, sharex=True, sharey=True,\n",
    "                         figsize=(1,3.3), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for ax, key in zip(axes.flat, lithology_numbers.keys()):\n",
    "    ax.plot(x, y)\n",
    "    ax.fill_betweenx(y, 0, 1, facecolor=lithology_numbers[key]['color'], hatch=lithology_numbers[key]['hatch'])\n",
    "    ax.set_xlim(0, 0.1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(str(lithology_numbers[key]['lith']))   \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.35)\n",
    "plt.savefig(\"facies_guide.tiff\", dpi=300)   \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_numbers = {\n",
    "                     1: {'lith':'Gurpi', 'lith_num':1, 'hatch':'', 'color':'#A9E2F3'},\n",
    "                     2: {'lith':'Ilam', 'lith_num':2, 'hatch':'', 'color':'#585858'},\n",
    "                     3: {'lith':'Lafan', 'lith_num':3, 'hatch':'', 'color':'#F7FE2E'},\n",
    "                     4: {'lith':'Sarvak', 'lith_num':4, 'hatch':'', 'color':'#D8D8D8'},\n",
    "                     5: {'lith':'Kazhdumi', 'lith_num':5, 'hatch':'', 'color':'#81F781'},}\n",
    "formation_numbers[4]['color']\n",
    "df_lith = pd.DataFrame.from_dict(formation_numbers, orient='index')\n",
    "df_lith.index.name = 'Formation'\n",
    "df_lith\n",
    "y = [0, 1]\n",
    "x = [1, 1]\n",
    "fig, axes = plt.subplots(ncols=1,nrows=5, sharex=True, sharey=True,\n",
    "                         figsize=(1,4), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for ax, key in zip(axes.flat, formation_numbers.keys()):\n",
    "    ax.plot(x, y)\n",
    "    ax.fill_betweenx(y, 0, 1, facecolor=formation_numbers[key]['color'], hatch=formation_numbers[key]['hatch'])\n",
    "    ax.set_xlim(0, 0.1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(str(formation_numbers[key]['lith'])) \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.35)\n",
    "plt.savefig(\"formation_guide.tiff\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations = {\"Gurpi\":[2350.618, 2659.99],\n",
    "              \"Ilam\": [2660.142, 2757.938],\n",
    "              \"Lafan\": [2758.135, 2768.956],\n",
    "              \"Sarvak\": [2769.108, 3398.977]}\n",
    "zone_colours = ['#A9E2F3',\n",
    "       '#585858','#F7FE2E','#D8D8D8', '#00FFFF']\n",
    "def makeplot(well, top_depth, bottom_depth, formations):\n",
    "    fig, ax = plt.subplots(figsize=(3.8, 8))\n",
    "\n",
    "    ax1 = plt.subplot2grid((1, 3), (0, 0), rowspan=1, colspan = 1)\n",
    "    \n",
    "    ax2 = plt.subplot2grid((1, 3), (0, 1), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax10 = ax1.twiny()\n",
    "    ax10.xaxis.set_visible(False)\n",
    "    ax1.plot(well[\"CGR\"], well['Depth'], color = \"#FF0000\", linewidth = 0.8)\n",
    "    ax1.set_xlabel(\"GR (GAPI)\")\n",
    "    ax1.xaxis.label.set_color(\"#FF0000\")\n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_ylabel(\"TVD (m)\")\n",
    "    ax1.tick_params(axis='x', colors=\"#FF0000\")\n",
    "    ax1.spines[\"top\"].set_edgecolor(\"#FF0000\")\n",
    "    ax1.title.set_color('#FF0000')\n",
    "    ax1.set_xticks([0, 75, 150])\n",
    "    left_col_value = 0\n",
    "    right_col_value = 150\n",
    "    span = abs(left_col_value - right_col_value)\n",
    "    cmap = plt.get_cmap('hot_r')\n",
    "    color_index = np.arange(left_col_value, right_col_value, span / 100)\n",
    "    for index in sorted(color_index):\n",
    "        index_value = (index - left_col_value)/span\n",
    "        color = cmap(index_value) \n",
    "    ax2.plot(well[\"LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax2.set_xlabel(\"GML\")\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.xaxis.label.set_color(\"black\")\n",
    "    ax2.tick_params(axis='x', colors=\"black\")\n",
    "    ax2.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax2.fill_betweenx(well['Depth'], 0, well['LITHOLOGY'], where=(well['LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax2.set_xticks([])\n",
    "    for ax in [ax1, ax2]:\n",
    "        ax.set_ylim(bottom_depth, top_depth)\n",
    "        ax.grid(which='major', color='lightgrey', linestyle='-')\n",
    "        ax.xaxis.set_ticks_position(\"top\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "        ax.spines[\"top\"].set_position((\"axes\", 1.01))\n",
    "    for ax in [ax1]:\n",
    "        for depth, colour in zip(formations.values(), zone_colours):\n",
    "            ax.axhspan(depth[0], depth[1], color=colour, alpha=0.5)\n",
    "    for ax in [ ax2]:\n",
    "        plt.setp(ax.get_yticklabels(), visible = False)\n",
    "    for label, formation_mid in zip(formations_dict.keys(),\n",
    "                                    formation_midpoints):\n",
    "        ax1.text(5, formation_mid, label, rotation=0,\n",
    "                verticalalignment='center', fontweight='bold',\n",
    "                fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace = 0.22)\n",
    "    fig.savefig(\"total.tiff\", dpi=300)\n",
    "df = 'df_raw.csv'\n",
    "df = pd.read_csv(df)\n",
    "makeplot(df, 2350, 3398, formations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2rbL8bSGDHy3"
   },
   "source": [
    "### Split the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jJqepif-Bv1s",
    "outputId": "b22ad81e-7e40-4ea7-ee8e-97fe9b58679a"
   },
   "outputs": [],
   "source": [
    "data = well_5.merge(well_1, on='Depth', suffixes = (None,'_1'))\n",
    "print(data.shape)\n",
    "data = data.merge(well_2, on='Depth', suffixes = (None,'_2'))\n",
    "print(data.shape)\n",
    "data = data.merge(well_3, on='Depth', suffixes = (None,'_3'))\n",
    "print(data.shape)\n",
    "data = data.merge(well_4, on='Depth', suffixes = (None,'_4'))\n",
    "print(data.shape)\n",
    "column_indices = {name: i for i, name in enumerate(data.columns)}\n",
    "n = len(data)\n",
    "train_df = data[data.Depth <= 2779.9284]\n",
    "val_df = data[(data.Depth > 2779.9284) & (data.Depth <= 2900.)]\n",
    "test_df = data[data.Depth > 2900.]\n",
    "num_features = data.shape[1]\n",
    "train_df.shape, val_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f=test_df['Facies']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:04.291955Z",
     "iopub.status.busy": "2023-07-27T04:27:04.291732Z",
     "iopub.status.idle": "2023-07-27T04:27:04.330937Z",
     "shell.execute_reply": "2023-07-27T04:27:04.330220Z"
    },
    "id": "Eji6njXvHusN"
   },
   "outputs": [],
   "source": [
    "train_mean = train_df.mean()\n",
    "train_std = train_df.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:04.334797Z",
     "iopub.status.busy": "2023-07-27T04:27:04.334556Z",
     "iopub.status.idle": "2023-07-27T04:27:09.417027Z",
     "shell.execute_reply": "2023-07-27T04:27:09.416293Z"
    },
    "id": "T0UYEnkwm8Fe",
    "outputId": "ebb3b51d-afc3-44c5-dd27-6cf60d17d6ec"
   },
   "outputs": [],
   "source": [
    "df_std = (data - train_mean) / train_std\n",
    "df_std = df_std.melt(var_name='Column', value_name='Normalized')\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.violinplot(x='Column', y='Normalized', data=df_std)\n",
    "_ = ax.set_xticklabels(data.keys(), rotation=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZBBmdxZ2HgfJ"
   },
   "source": [
    "## Data windowing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WindowGenerator():\n",
    "    def __init__(self, input_width, label_width, shift,\n",
    "                 train_df, val_df, test_df,\n",
    "                 label_columns=None):\n",
    "        # Raw datasets\n",
    "        self.train_df = train_df\n",
    "        self.val_df = val_df\n",
    "        self.test_df = test_df\n",
    "        self.label_columns = label_columns\n",
    "        if label_columns is not None:\n",
    "            self.label_columns_indices = {name: i for i, name in enumerate(label_columns)}\n",
    "        self.column_indices = {name: i for i, name in enumerate(train_df.columns)}\n",
    "        self.input_width = input_width\n",
    "        self.label_width = label_width\n",
    "        self.shift = shift\n",
    "        self.total_window_size = input_width + shift\n",
    "        self.input_slice = slice(0, input_width)\n",
    "        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n",
    "        self.label_start = self.total_window_size - self.label_width\n",
    "        self.labels_slice = slice(self.label_start, None)\n",
    "        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n",
    "    def __repr__(self):\n",
    "        return '\\n'.join([\n",
    "            f'Total window size: {self.total_window_size}',\n",
    "            f'Input indices: {self.input_indices}',\n",
    "            f'Label indices: {self.label_indices}',\n",
    "            f'Label column name(s): {self.label_columns}'])\n",
    "    def split_window(self, features):\n",
    "        inputs = features[:, self.input_slice, :]\n",
    "        labels = features[:, self.labels_slice, :]\n",
    "        if self.label_columns is not None:\n",
    "            labels = tf.stack(\n",
    "                [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "            inputs = tf.stack(\n",
    "                [inputs[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "                axis=-1)\n",
    "        mean = tf.reduce_mean(inputs, axis=1, keepdims=True)\n",
    "        std = tf.math.reduce_std(inputs, axis=1, keepdims=True) + 1e-6  \n",
    "        inputs = (inputs - mean) / std\n",
    "        return inputs, labels\n",
    "    def make_dataset(self, data):\n",
    "        data = np.array(data, dtype=np.float32)\n",
    "        ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "            data=data,\n",
    "            targets=None,\n",
    "            sequence_length=self.total_window_size,\n",
    "            sequence_stride=1,\n",
    "            shuffle=True,\n",
    "            batch_size=32)\n",
    "        ds = ds.map(self.split_window)\n",
    "        return ds\n",
    "    @property\n",
    "    def train(self):\n",
    "        return self.make_dataset(self.train_df)\n",
    "    @property\n",
    "    def val(self):\n",
    "        return self.make_dataset(self.val_df)\n",
    "    @property\n",
    "    def test(self):\n",
    "        return self.make_dataset(self.test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.430763Z",
     "iopub.status.busy": "2023-07-27T04:27:09.430546Z",
     "iopub.status.idle": "2023-07-27T04:27:09.435057Z",
     "shell.execute_reply": "2023-07-27T04:27:09.434430Z"
    },
    "id": "IsM5kRkz0UwK",
    "outputId": "4d828084-121d-4124-980a-b1ddaa42f114"
   },
   "outputs": [],
   "source": [
    "w1 = WindowGenerator(\n",
    "    input_width=24,\n",
    "    label_width=1,\n",
    "    shift=24,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    label_columns=['CGR', 'SGR', 'Facies'])\n",
    "w1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.438109Z",
     "iopub.status.busy": "2023-07-27T04:27:09.437602Z",
     "iopub.status.idle": "2023-07-27T04:27:09.441855Z",
     "shell.execute_reply": "2023-07-27T04:27:09.441298Z"
    },
    "id": "viwKsYeAKFUn",
    "outputId": "21ba6f37-51dc-45a2-d3cb-e4a0d4117ebf"
   },
   "outputs": [],
   "source": [
    "w2 = WindowGenerator(\n",
    "    input_width=8,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    label_columns=['CGR', 'SGR', 'Facies'])\n",
    "w2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.444742Z",
     "iopub.status.busy": "2023-07-27T04:27:09.444531Z",
     "iopub.status.idle": "2023-07-27T04:27:09.449021Z",
     "shell.execute_reply": "2023-07-27T04:27:09.448472Z"
    },
    "id": "W4KbxfzqkXPW"
   },
   "outputs": [],
   "source": [
    "def split_window(self, features):\n",
    "    inputs = features[:, self.input_slice, :]\n",
    "    labels = features[:, self.labels_slice, :]\n",
    "    if self.label_columns is not None:\n",
    "        labels = tf.stack(\n",
    "            [labels[:, :, self.column_indices[name]] for name in self.label_columns],\n",
    "            axis=-1)\n",
    "    inputs.set_shape([None, self.input_width, None])\n",
    "    labels.set_shape([None, self.label_width, None])\n",
    "    return inputs, labels\n",
    "WindowGenerator.split_window = split_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.451969Z",
     "iopub.status.busy": "2023-07-27T04:27:09.451748Z",
     "iopub.status.idle": "2023-07-27T04:27:09.468798Z",
     "shell.execute_reply": "2023-07-27T04:27:09.468238Z"
    },
    "id": "YeCWbq6KLmL7",
    "outputId": "0f57aba7-564e-41ad-df03-ea92562e07bf"
   },
   "outputs": [],
   "source": [
    "example_window = tf.stack([np.array(train_df[:w2.total_window_size]),\n",
    "                           np.array(train_df[100:100+w2.total_window_size]),\n",
    "                           np.array(train_df[200:200+w2.total_window_size])])\n",
    "example_inputs, example_labels = w2.split_window(example_window)\n",
    "print('All shapes are: (batch, time, features)')\n",
    "print(f'Window shape: {example_window.shape}')\n",
    "print(f'Inputs shape: {example_inputs.shape}')\n",
    "print(f'Labels shape: {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.471813Z",
     "iopub.status.busy": "2023-07-27T04:27:09.471598Z",
     "iopub.status.idle": "2023-07-27T04:27:09.474570Z",
     "shell.execute_reply": "2023-07-27T04:27:09.474016Z"
    },
    "id": "fmgd1qkYUWT7"
   },
   "outputs": [],
   "source": [
    "w2.example = example_inputs, example_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.477329Z",
     "iopub.status.busy": "2023-07-27T04:27:09.477093Z",
     "iopub.status.idle": "2023-07-27T04:27:09.483378Z",
     "shell.execute_reply": "2023-07-27T04:27:09.482808Z"
    },
    "id": "jIrYccI-Hm3B"
   },
   "outputs": [],
   "source": [
    "def plot(self, plot_col = ['CGR', 'SGR', 'Facies'], model=None, max_subplots=3):\n",
    "  inputs, labels = self.example\n",
    "  plt.figure(figsize=(12, 8))\n",
    "  cols = [self.column_indices[col] for col in plot_col]\n",
    "  max_n = min(max_subplots, len(inputs))\n",
    "  for n in range(max_n):\n",
    "    plot_col_index = self.column_indices[plot_col[n]]\n",
    "    plt.subplot(max_n, 1, n+1)\n",
    "    plt.ylabel(f'{plot_col[n]}')\n",
    "    plt.plot(self.input_indices, inputs[n, :, plot_col_index],\n",
    "             label='Inputs', marker='.', zorder=-10)\n",
    "    if self.label_columns:\n",
    "      label_col_index = self.label_columns_indices.get(plot_col[n], None)\n",
    "    else:\n",
    "      label_col_index = plot_col_index\n",
    "    if label_col_index is None:\n",
    "      continue\n",
    "    plt.scatter(self.label_indices, labels[n, :, label_col_index],\n",
    "                edgecolors='k', label='Labels', c='#2ca02c', s=64)\n",
    "    if model is not None:\n",
    "      predictions = model(inputs)\n",
    "      plt.scatter(self.label_indices, predictions[n, :, label_col_index],\n",
    "                  marker='X', edgecolors='k', label='Predictions',\n",
    "                  c='#ff7f0e', s=64)\n",
    "    plt.legend()\n",
    "    if plot_col[n] == \"Facies\":\n",
    "      plt.ylim(bottom=0, top=5)\n",
    "    else:\n",
    "      plt.ylim(bottom=-10, top=100)\n",
    "  plt.xlabel('Depth')\n",
    "WindowGenerator.plot = plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_plot(history):\n",
    "  fig, ax = plt.subplots(1, 2)\n",
    "  fig.set_size_inches(10, 4)\n",
    "  ax[0].plot(history['loss'], label = 'loss')\n",
    "  ax[0].plot(history['val_loss'], label = 'Val_loss')\n",
    "  ax[0].legend()\n",
    "  ax[0].set_xlabel('EPOCHS')\n",
    "  ax[0].set_ylabel(\"Loss\")\n",
    "  ax[1].plot(history[\"mean_absolute_percentage_error\"], label = \"MAPE\")\n",
    "  ax[1].plot(history[\"val_mean_absolute_percentage_error\"], label = 'Val-MAPE')\n",
    "  ax[1].legend()\n",
    "  ax[1].set_xlabel('EPOCHS')\n",
    "  ax[1].set_ylabel(\"MAPE\")\n",
    "  plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:09.486153Z",
     "iopub.status.busy": "2023-07-27T04:27:09.485942Z",
     "iopub.status.idle": "2023-07-27T04:27:09.947151Z",
     "shell.execute_reply": "2023-07-27T04:27:09.946432Z"
    },
    "id": "XjTqUnglOOni",
    "outputId": "7d40858a-74c4-44b6-f413-649205d22915"
   },
   "outputs": [],
   "source": [
    "w2.plot(plot_col = ['CGR', 'SGR', 'Facies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.475584Z",
     "iopub.status.busy": "2023-07-27T04:27:10.475131Z",
     "iopub.status.idle": "2023-07-27T04:27:10.479530Z",
     "shell.execute_reply": "2023-07-27T04:27:10.478964Z"
    },
    "id": "35qoSQeRVfJg"
   },
   "outputs": [],
   "source": [
    "def make_dataset(self, data):\n",
    "  data = np.array(data, dtype=np.float32)\n",
    "  ds = tf.keras.utils.timeseries_dataset_from_array(\n",
    "      data=data,\n",
    "      targets=None,\n",
    "      sequence_length=self.total_window_size,\n",
    "      sequence_stride=1,\n",
    "      shuffle=False,\n",
    "      batch_size=32,)\n",
    "  ds = ds.map(self.split_window)\n",
    "  return ds\n",
    "WindowGenerator.make_dataset = make_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.482888Z",
     "iopub.status.busy": "2023-07-27T04:27:10.482340Z",
     "iopub.status.idle": "2023-07-27T04:27:10.487490Z",
     "shell.execute_reply": "2023-07-27T04:27:10.486874Z"
    },
    "id": "2jZ2KkqGCfzu"
   },
   "outputs": [],
   "source": [
    "@property\n",
    "def train(self):\n",
    "  return self.make_dataset(self.train_df)\n",
    "@property\n",
    "def val(self):\n",
    "  return self.make_dataset(self.val_df)\n",
    "@property\n",
    "def test(self):\n",
    "  return self.make_dataset(self.test_df)\n",
    "@property\n",
    "def example(self):\n",
    "  result = getattr(self, '_example', None)\n",
    "  if result is None:\n",
    "    result = next(iter(self.train))\n",
    "    self._example = result\n",
    "  return result\n",
    "WindowGenerator.train = train\n",
    "WindowGenerator.val = val\n",
    "WindowGenerator.test = test\n",
    "WindowGenerator.example = example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.490621Z",
     "iopub.status.busy": "2023-07-27T04:27:10.490217Z",
     "iopub.status.idle": "2023-07-27T04:27:10.614889Z",
     "shell.execute_reply": "2023-07-27T04:27:10.614276Z"
    },
    "id": "daJ0-U383YVs",
    "outputId": "f99f7128-201e-4bd1-a32e-153c900fc9b3",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "w2.train.element_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKTx3_Z7ua-n"
   },
   "source": [
    "Iterating over a `Dataset` yields concrete batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.617933Z",
     "iopub.status.busy": "2023-07-27T04:27:10.617702Z",
     "iopub.status.idle": "2023-07-27T04:27:10.727720Z",
     "shell.execute_reply": "2023-07-27T04:27:10.726962Z"
    },
    "id": "6gtKXEgf4Iml",
    "outputId": "637a4606-496d-4af2-dcc4-da2936349dcb"
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in w2.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyuGuJUgjUK3"
   },
   "source": [
    "## Single step models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.731234Z",
     "iopub.status.busy": "2023-07-27T04:27:10.730616Z",
     "iopub.status.idle": "2023-07-27T04:27:10.735370Z",
     "shell.execute_reply": "2023-07-27T04:27:10.734724Z"
    },
    "id": "G5QX1G1JTPCr",
    "outputId": "f1f85c2e-1f52-44ab-82e1-3b620eaa55bf",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "single_step_window = WindowGenerator(\n",
    "    input_width=1,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    label_columns=['CGR', 'SGR', 'Facies'])\n",
    "single_step_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:27:10.738626Z",
     "iopub.status.busy": "2023-07-27T04:27:10.738149Z",
     "iopub.status.idle": "2023-07-27T04:27:10.849969Z",
     "shell.execute_reply": "2023-07-27T04:27:10.849285Z"
    },
    "id": "Do4ILUaBF8oc",
    "outputId": "fee8e284-1b01-4fe8-df7c-ba971c4cd9a5",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for example_inputs, example_labels in single_step_window.train.take(1):\n",
    "  print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n",
    "  print(f'Labels shape (batch, time, features): {example_labels.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VgY4wzdzS1Z"
   },
   "source": [
    "### Normalize Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-Yl5aVjlzWdo"
   },
   "outputs": [],
   "source": [
    "class norm_layer(tf.keras.layers.Layer):\n",
    "  def __init__(self, M, S):\n",
    "    super(norm_layer, self).__init__()\n",
    "    self.mean = M\n",
    "    self.std  = S\n",
    "  def call(self, inp):\n",
    "    return (inp - self.mean) / self.std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_EPOCHS = 200\n",
    "class HybridCLFLoss(tf.keras.losses.Loss):\n",
    "    def __init__(self, model, lambda_l1=1e-6, lambda_dr=1e-5, name=\"hybrid_clf_loss\"):\n",
    "        super().__init__(name=name)\n",
    "        self.model = model\n",
    "        self.lambda_l1 = lambda_l1\n",
    "        self.lambda_dr = lambda_dr\n",
    "    def call(self, y_true, y_pred, sample_weight=None):\n",
    "        if sample_weight is not None:\n",
    "            weighted_error = sample_weight * tf.square(y_true - y_pred)\n",
    "            mse = tf.reduce_mean(weighted_error)\n",
    "        else:\n",
    "            mse = tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "        mse = tf.where(tf.math.is_nan(mse), tf.zeros_like(mse), mse)\n",
    "        reg_loss = tf.add_n([\n",
    "            tf.reduce_sum(tf.abs(layer.kernel))\n",
    "            for layer in self.model.layers if isinstance(layer, tf.keras.layers.Dense)\n",
    "        ])\n",
    "        reg_loss = tf.where(tf.math.is_nan(reg_loss), tf.zeros_like(reg_loss), reg_loss)\n",
    "        if len(y_pred.shape) >= 2 and tf.shape(y_pred)[1] > 1:\n",
    "            diff = y_pred[:, 1:] - y_pred[:, :-1]\n",
    "            dr_loss = tf.reduce_mean(tf.square(diff))\n",
    "        else:\n",
    "            dr_loss = 0.0\n",
    "        dr_loss = tf.where(tf.math.is_nan(dr_loss), tf.zeros_like(dr_loss), dr_loss)\n",
    "        return mse + self.lambda_l1 * reg_loss + self.lambda_dr * dr_loss\n",
    "class WeightedLossWrapper(tf.keras.losses.Loss):\n",
    "    def __init__(self, base_loss, sample_weights):\n",
    "        super().__init__()\n",
    "        self.base_loss = base_loss\n",
    "        self.sample_weights = tf.convert_to_tensor(sample_weights, dtype=tf.float32)\n",
    "    def call(self, y_true, y_pred):\n",
    "        return self.base_loss(y_true, y_pred, sample_weight=self.sample_weights)\n",
    "def compile_and_fit(model, window, patience=50, lambda_l1=1e-6, lambda_dr=1e-5, sample_weights=None):\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=patience,\n",
    "        mode='min',\n",
    "        restore_best_weights=True)\n",
    "    base_loss = HybridCLFLoss(model=model, lambda_l1=lambda_l1, lambda_dr=lambda_dr)\n",
    "    if sample_weights is not None:\n",
    "        loss_fn = WeightedLossWrapper(base_loss, sample_weights)\n",
    "    else:\n",
    "        loss_fn = lambda y_true, y_pred: base_loss(y_true, y_pred)\n",
    "    model.compile(\n",
    "        loss=loss_fn,\n",
    "        optimizer=tf.keras.optimizers.SGD(learning_rate=0.001),\n",
    "        metrics=[tf.keras.metrics.MeanAbsolutePercentageError()])\n",
    "    history = model.fit(\n",
    "        window.train,\n",
    "        validation_data=window.val,\n",
    "        epochs=MAX_EPOCHS,\n",
    "        callbacks=[early_stopping])\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TwtN2NGC6P2g"
   },
   "outputs": [],
   "source": [
    "performance = {}\n",
    "val_performance = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aer1vV8t7KTj",
    "outputId": "ab3feb89-7f84-441c-874b-ee19f2e626e0"
   },
   "outputs": [],
   "source": [
    "wide_window = WindowGenerator(\n",
    "    input_width=24,\n",
    "    label_width=24,\n",
    "    shift=1,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    label_columns=['CGR', 'SGR', 'Facies'])\n",
    "wide_window"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W18e6da1cNbw"
   },
   "source": [
    "### MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D_s = shuffle(train_df, random_state=42)\n",
    "D_s = D_s.drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "mlp_model = tf.keras.Sequential([\n",
    "    norm_layer(train_mean, train_std),\n",
    "    tf.keras.layers.Dense(units=512, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=128, activation='relu'),\n",
    "    tf.keras.layers.Dense(units=3)])\n",
    "compile_and_fit(mlp_model, single_step_window)\n",
    "mlp_model.save_weights(\"pretrained_weights.h5\")  \n",
    "mlp_model.load_weights(\"pretrained_weights.h5\")\n",
    "compile_and_fit(mlp_model, single_step_window)   \n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "num_samples = len(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(num_samples)\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "mlp_model.load_weights(\"pretrained_weights.h5\")\n",
    "history = compile_and_fit(mlp_model, single_step_window)\n",
    "val_performance['Dense'] = mlp_model.evaluate(single_step_window.val, verbose=0)\n",
    "performance['Dense'] = mlp_model.evaluate(single_step_window.test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "yEcR_4_mXjJO",
    "outputId": "76850f59-0c4f-4483-c98c-429cbbe96746"
   },
   "outputs": [],
   "source": [
    "loss_plot(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 701
    },
    "id": "BOsYSFaUK7lf",
    "outputId": "647b2794-078a-4d55-ffbd-d2d91f28d20c"
   },
   "outputs": [],
   "source": [
    "wide_window.plot(model = mlp_model, max_subplots=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "H4crpOcoMlSe"
   },
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D_s = shuffle(train_df, random_state=42).drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "lstm_model = tf.keras.Sequential([\n",
    "    norm_layer(train_mean, train_std),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=True),\n",
    "    tf.keras.layers.Dense(128, activation='relu'), \n",
    "    tf.keras.layers.Dense(3),])\n",
    "_ = lstm_model(single_step_window.example[0])  \n",
    "compile_and_fit(lstm_model, single_step_window)\n",
    "lstm_model.save_weights(\"lstm_pretrained_weights.h5\") \n",
    "lstm_model.load_weights(\"lstm_pretrained_weights.h5\")\n",
    "compile_and_fit(lstm_model, single_step_window)\n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(len(gmm_data))\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "lstm_model.load_weights(\"lstm_pretrained_weights.h5\")\n",
    "compile_and_fit(lstm_model, single_step_window)\n",
    "val_performance['LSTM'] = lstm_model.evaluate(single_step_window.val, verbose=0)\n",
    "performance['LSTM'] = lstm_model.evaluate(single_step_window.test, verbose=0)\n",
    "loss_plot(history.history)\n",
    "wide_window.plot(model=lstm_model, max_subplots=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class TransformerBlock(layers.Layer):\n",
    "    def __init__(self, embed_dim, num_heads, ff_dim, rate=0.1):\n",
    "        super().__init__()\n",
    "        self.att = layers.MultiHeadAttention(num_heads=num_heads, key_dim=embed_dim)\n",
    "        self.ffn = tf.keras.Sequential([\n",
    "            layers.Dense(ff_dim, activation=\"gelu\"),\n",
    "            layers.Dense(embed_dim),])\n",
    "        self.layernorm1 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.dropout1 = layers.Dropout(rate)\n",
    "        self.dropout2 = layers.Dropout(rate)\n",
    "    def call(self, inputs, training):\n",
    "        attn_output = self.att(inputs, inputs)\n",
    "        attn_output = self.dropout1(attn_output, training=training)\n",
    "        out1 = self.layernorm1(inputs + attn_output)\n",
    "        ffn_output = self.ffn(out1)\n",
    "        ffn_output = self.dropout2(ffn_output, training=training)\n",
    "        return self.layernorm2(out1 + ffn_output)\n",
    "class PositionalEncoding(layers.Layer):\n",
    "    def __init__(self, position, d_model):\n",
    "        super().__init__()\n",
    "        self.pos_encoding = self.positional_encoding(position, d_model)\n",
    "    def get_angles(self, position, i, d_model):\n",
    "        angles = 1 / tf.pow(10000, (2 * (i // 2)) / tf.cast(d_model, tf.float32))\n",
    "        return position * angles\n",
    "    def positional_encoding(self, position, d_model):\n",
    "        angle_rads = self.get_angles(\n",
    "            position=tf.range(position, dtype=tf.float32)[:, tf.newaxis],\n",
    "            i=tf.range(d_model, dtype=tf.float32)[tf.newaxis, :],\n",
    "            d_model=d_model)\n",
    "        sines = tf.math.sin(angle_rads[:, 0::2])\n",
    "        cosines = tf.math.cos(angle_rads[:, 1::2])\n",
    "        pos_encoding = tf.concat([sines, cosines], axis=-1)\n",
    "        pos_encoding = pos_encoding[tf.newaxis, ...]\n",
    "        return tf.cast(pos_encoding, tf.float32)\n",
    "    def call(self, inputs):\n",
    "        return inputs + self.pos_encoding[:, :tf.shape(inputs)[1], :]\n",
    "def create_transformer_model(input_shape, output_dim, num_layers=3, d_model=128, num_heads=8, ff_dim=256, dropout=0.1):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = norm_layer(train_mean, train_std)(inputs)\n",
    "    x = layers.Dense(d_model)(x)\n",
    "    x = PositionalEncoding(input_shape[0], d_model)(x)\n",
    "    for _ in range(num_layers):\n",
    "        x = TransformerBlock(d_model, num_heads, ff_dim, dropout)(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.1)(x)\n",
    "    outputs = layers.Dense(output_dim)(x)\n",
    "    outputs = layers.Reshape([1, output_dim])(outputs)\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "D_s = shuffle(train_df, random_state=42).drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "input_shape = single_step_window.example[0].shape[1:]  \n",
    "output_dim = 3\n",
    "transformer_model = create_transformer_model(input_shape, output_dim)\n",
    "_ = transformer_model(single_step_window.example[0])  \n",
    "compile_and_fit(transformer_model, single_step_window)\n",
    "transformer_model.save_weights(\"transformer_pretrained_weights.h5\")\n",
    "transformer_model.load_weights(\"transformer_pretrained_weights.h5\")\n",
    "compile_and_fit(transformer_model, single_step_window)\n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(len(gmm_data))\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "transformer_model.load_weights(\"transformer_pretrained_weights.h5\")\n",
    "compile_and_fit(transformer_model, single_step_window)\n",
    "val_performance['transformer_model'] = transformer_model.evaluate(single_step_window.val, verbose=0)\n",
    "performance['transformer_model'] = transformer_model.evaluate(single_step_window.test, verbose=0)\n",
    "transformer_model.summary()\n",
    "loss_plot(history.history)\n",
    "single_step_window.plot(model=transformer_model, max_subplots=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pYglOCKehi8F"
   },
   "source": [
    "### Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 549
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:32:20.754603Z",
     "iopub.status.busy": "2023-07-27T04:32:20.754334Z",
     "iopub.status.idle": "2023-07-27T04:32:20.950975Z",
     "shell.execute_reply": "2023-07-27T04:32:20.950322Z"
    },
    "id": "JjEkt488hi8I",
    "outputId": "f3b47ccb-1dad-4885-9474-d1f8f00f5d68",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "metric_name = 'mean_absolute_percentage_error'\n",
    "metric_index = lstm_model.metrics_names.index('mean_absolute_percentage_error')\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "plt.ylabel('mean_absolute_percentage_error')\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(),\n",
    "           rotation=45)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:32:20.954254Z",
     "iopub.status.busy": "2023-07-27T04:32:20.953763Z",
     "iopub.status.idle": "2023-07-27T04:32:20.957436Z",
     "shell.execute_reply": "2023-07-27T04:32:20.956868Z"
    },
    "id": "cBMCpsdphi8L",
    "outputId": "b84a5801-fef0-4063-f178-9cccfb62bb3b"
   },
   "outputs": [],
   "source": [
    "for name, value in performance.items():\n",
    "  print(f'{name:10}: {value[1]:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eYokb7Om2YbK"
   },
   "source": [
    "## Multi-step models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 770
    },
    "execution": {
     "iopub.execute_input": "2023-07-27T04:35:47.217020Z",
     "iopub.status.busy": "2023-07-27T04:35:47.216810Z",
     "iopub.status.idle": "2023-07-27T04:35:47.758956Z",
     "shell.execute_reply": "2023-07-27T04:35:47.758231Z"
    },
    "id": "1cFYtsz6XiGw",
    "outputId": "0cd0757a-59fd-4dbc-9619-7f33e00fb81c",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "multi_window = WindowGenerator(\n",
    "    input_width=8,\n",
    "    label_width=1,\n",
    "    shift=1,\n",
    "    train_df=train_df,\n",
    "    val_df=val_df,\n",
    "    test_df=test_df,\n",
    "    label_columns=['CGR', 'SGR', 'Facies'])\n",
    "multi_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sQaqBAUSElkX"
   },
   "outputs": [],
   "source": [
    "val_performance = {}\n",
    "performance = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi2TMHk2IRrh"
   },
   "source": [
    "## MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D_s = shuffle(train_df, random_state=42).drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "\n",
    "# Step 2: Define and pre-train the MLP model on D_s\n",
    "multi_mlp_model = tf.keras.Sequential([\n",
    "    norm_layer(train_mean, train_std),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Reshape([1, -1]),])\n",
    "_ = multi_mlp_model(multi_window.example[0])  \n",
    "compile_and_fit(multi_mlp_model, multi_window)\n",
    "multi_mlp_model.save_weights(\"multi_mlp_pretrained_weights.h5\")  # Save θ_p\n",
    "multi_mlp_model.load_weights(\"multi_mlp_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_mlp_model, multi_window)\n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(len(gmm_data))\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "multi_mlp_model.load_weights(\"multi_mlp_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_mlp_model, multi_window)\n",
    "val_performance['mlp'] = multi_mlp_model.evaluate(multi_window.val, verbose=0)\n",
    "performance['mlp'] = multi_mlp_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_mlp_model.summary()\n",
    "loss_plot(history.history)\n",
    "multi_window.plot(model=multi_mlp_model, max_subplots=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "weBjeZAFJOP4"
   },
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D_s = shuffle(train_df, random_state=42).drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "multi_lstm_model = tf.keras.Sequential([\n",
    "    norm_layer(train_mean, train_std),\n",
    "    tf.keras.layers.LSTM(32, return_sequences=False),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(3),\n",
    "    tf.keras.layers.Reshape([1, -1]),])\n",
    "_ = multi_lstm_model(multi_window.example[0])\n",
    "compile_and_fit(multi_lstm_model, multi_window)\n",
    "multi_lstm_model.save_weights(\"multi_lstm_pretrained_weights.h5\") \n",
    "multi_lstm_model.load_weights(\"multi_lstm_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_lstm_model, multi_window)\n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(len(gmm_data))\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "multi_lstm_model.load_weights(\"multi_lstm_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_lstm_model, multi_window)\n",
    "val_performance['LSTM'] = multi_lstm_model.evaluate(multi_window.val, verbose=0)\n",
    "performance['LSTM'] = multi_lstm_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_lstm_model.summary()\n",
    "loss_plot(history.history)\n",
    "multi_window.plot(model=multi_lstm_model, max_subplots=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "D_s = shuffle(train_df, random_state=42).drop(columns=[\"Depth\"])\n",
    "D_t = val_df.drop(columns=[\"Depth\"])\n",
    "input_shape = multi_window.example[0].shape[1:]  \n",
    "output_dim = 3  \n",
    "multi_transformer_model = create_transformer_model(input_shape, output_dim)\n",
    "_ = multi_transformer_model(multi_window.example[0])  \n",
    "compile_and_fit(multi_transformer_model, multi_window)\n",
    "multi_transformer_model.save_weights(\"multi_transformer_pretrained_weights.h5\")  \n",
    "multi_transformer_model.load_weights(\"multi_transformer_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_transformer_model, multi_window)\n",
    "gmm_data = train_df.drop(columns=[\"Depth\"])\n",
    "gmm = GaussianMixture(n_components=5, covariance_type='full', random_state=42)\n",
    "gmm.fit(gmm_data)\n",
    "synthetic_samples, _ = gmm.sample(len(gmm_data))\n",
    "D_syn = pd.DataFrame(synthetic_samples, columns=gmm_data.columns)\n",
    "D_o = train_df.drop(columns=[\"Depth\"])\n",
    "D_c = pd.concat([D_o, D_syn], ignore_index=True)\n",
    "multi_transformer_model.load_weights(\"multi_transformer_pretrained_weights.h5\")\n",
    "compile_and_fit(multi_transformer_model, multi_window)\n",
    "val_performance['Transformer'] = multi_transformer_model.evaluate(multi_window.val, verbose=0)\n",
    "performance['Transformer'] = multi_transformer_model.evaluate(multi_window.test, verbose=0)\n",
    "multi_transformer_model.summary()\n",
    "loss_plot(history.history)\n",
    "multi_window.plot(model=multi_transformer_model, max_subplots=2)\n",
    "def plot_model_structure(model, filename=\"model_structure.png\", show=True):\n",
    "    plot_model(model, to_file=filename, show_shapes=True, show_layer_names=True, \n",
    "               rankdir='TB', expand_nested=True, dpi=300)\n",
    "    img = plt.imread(filename)\n",
    "    fig = plt.figure(figsize=(12, 12), dpi=300)\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.savefig(filename, format='png', dpi=300, bbox_inches='tight')\n",
    "    if show:\n",
    "        display(Image(filename))\n",
    "    plt.close(fig)\n",
    "plot_model_structure(multi_transformer_model, filename=\"transformer_model_structure.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(len(performance))\n",
    "width = 0.3\n",
    "metric_name = 'mean_absolute_percentage_error'\n",
    "metric_index = multi_lstm_model.metrics_names.index(metric_name)\n",
    "val_mae = [v[metric_index] for v in val_performance.values()]\n",
    "test_mae = [v[metric_index] for v in performance.values()]\n",
    "plt.ylabel(metric_name)\n",
    "plt.bar(x - 0.17, val_mae, width, label='Validation')\n",
    "plt.bar(x + 0.17, test_mae, width, label='Test')\n",
    "plt.xticks(ticks=x, labels=performance.keys(), rotation=45)\n",
    "_ = plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name, value in performance.items():\n",
    "    print(f'{name:15}: {value[metric_index]:0.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "55bWvz6MMofQ"
   },
   "source": [
    "# Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iA3uwpq-05_z"
   },
   "outputs": [],
   "source": [
    "train = data[data.Depth < 2779.9284]\n",
    "test = data[data.Depth > 2779.9284]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gyHg7V6CsarH",
    "outputId": "7b38e64d-0277-4695-f30e-98b372a36cbe"
   },
   "outputs": [],
   "source": [
    "data.rename(columns={'Facies':'LITHOLOGY'}, inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "cqjxVCJpyxtY",
    "outputId": "fb9df8ad-8330-4f83-aea8-83b4afc409e5"
   },
   "outputs": [],
   "source": [
    "data = data.iloc[:, :4]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yqAJUWiAOlRA"
   },
   "outputs": [],
   "source": [
    "formations_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z_N1XZAbOYb1"
   },
   "outputs": [],
   "source": [
    "with open('Formation.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjspZs7srWij",
    "outputId": "de5509b1-aa90-4168-c2e0-f7b2b7f560b4"
   },
   "outputs": [],
   "source": [
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8moILWA3OYY9"
   },
   "outputs": [],
   "source": [
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EERDwgy2OYSc"
   },
   "outputs": [],
   "source": [
    "lithology_numbers = {\n",
    "                     1: {'lith':'argiLs', 'lith_num':1, 'hatch':'--|/', 'color':'#0000FF'},\n",
    "                     2: {'lith':'Sh', 'lith_num':2, 'hatch':'--', 'color':'#565051'},\n",
    "                     3: {'lith':'chkLs', 'lith_num':3, 'hatch':'.|.--', 'color':'#33caff'},\n",
    "                     4: {'lith':'Ls', 'lith_num':4, 'hatch':'--|', 'color':'#00FFFF'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}\n",
    "with open('Formation.csv', 'r') as file:\n",
    "    next(file) #skip header row\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]\n",
    "formations_dict\n",
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)\n",
    "lithology_numbers = {\n",
    "                     1: {'lith':'argiLs', 'lith_num':1, 'hatch':'...', 'color':'#0000FF'},\n",
    "                     2: {'lith':'Sh', 'lith_num':2, 'hatch':'--', 'color':'#565051'},\n",
    "                     3: {'lith':'chkLs', 'lith_num':3, 'hatch':'//', 'color':'#33caff'},\n",
    "                     4: {'lith':'Ls', 'lith_num':4, 'hatch':'o', 'color':'#00FFFF'}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [0, 1]\n",
    "x = [1, 1]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=1,nrows=4, sharex=True, sharey=True,\n",
    "                         figsize=(1,3.3), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for ax, key in zip(axes.flat, lithology_numbers.keys()):\n",
    "    ax.plot(x, y)\n",
    "    ax.fill_betweenx(y, 0, 1, facecolor=lithology_numbers[key]['color'], hatch=lithology_numbers[key]['hatch'])\n",
    "    ax.set_xlim(0, 0.1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(str(lithology_numbers[key]['lith']))  \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.35)\n",
    "plt.savefig(\"facies_guide.tiff\", dpi=300) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_numbers = {\n",
    "                     1: {'lith':'Gurpi', 'lith_num':1, 'hatch':'', 'color':'#A9E2F3'},\n",
    "                     2: {'lith':'Ilam', 'lith_num':2, 'hatch':'', 'color':'#585858'},\n",
    "                     3: {'lith':'Lafan', 'lith_num':3, 'hatch':'', 'color':'#F7FE2E'},\n",
    "                     4: {'lith':'Sarvak', 'lith_num':4, 'hatch':'', 'color':'#D8D8D8'},\n",
    "                     5: {'lith':'Kazhdumi', 'lith_num':5, 'hatch':'', 'color':'#81F781'}}\n",
    "formation_numbers[4]['color']\n",
    "df_lith = pd.DataFrame.from_dict(formation_numbers, orient='index')\n",
    "df_lith.index.name = 'Formation'\n",
    "df_lith\n",
    "y = [0, 1]\n",
    "x = [1, 1]\n",
    "fig, axes = plt.subplots(ncols=1,nrows=5, sharex=True, sharey=True,\n",
    "                         figsize=(1,4), subplot_kw={'xticks': [], 'yticks': []})\n",
    "for ax, key in zip(axes.flat, formation_numbers.keys()):\n",
    "    ax.plot(x, y)\n",
    "    ax.fill_betweenx(y, 0, 1, facecolor=formation_numbers[key]['color'], hatch=formation_numbers[key]['hatch'])\n",
    "    ax.set_xlim(0, 0.1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_title(str(formation_numbers[key]['lith'])) \n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(wspace = 0.35)\n",
    "plt.savefig(\"formation_guide.tiff\", dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2lbj3qY9OYVl"
   },
   "outputs": [],
   "source": [
    "formations = {\"Gurpi\":[2350.618, 2659.99],\n",
    "              \"Ilam\": [2660.142, 2757.938],\n",
    "              \"Lafan\": [2758.135, 2768.956],\n",
    "              \"Sarvak\": [2769.108, 3398.977]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EojApu_gMql6"
   },
   "outputs": [],
   "source": [
    "zone_colours = ['#A9E2F3',\n",
    "       '#585858','#F7FE2E','#D8D8D8', '#00FFFF']\n",
    "def makeplot(well, top_depth, bottom_depth, formations):\n",
    "    fig, ax = plt.subplots(figsize=(3.8, 8))\n",
    "    ax1 = plt.subplot2grid((1, 3), (0, 0), rowspan=1, colspan = 1)\n",
    "    ax12 = ax1.twiny()\n",
    "    ax2 = plt.subplot2grid((1, 3), (0, 1), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax3 = plt.subplot2grid((1, 3), (0, 2), rowspan=1, colspan = 1, sharey = ax1)\n",
    "\n",
    "    ax10 = ax1.twiny()\n",
    "    ax10.xaxis.set_visible(False)\n",
    "    ax1.plot(well[\"val CGR\"], well['Depth'], color = \"#088A08\", linewidth = 0.5)\n",
    "    ax1.set_xlabel(\"S-GR (GAPI)\")\n",
    "    ax1.xaxis.label.set_color(\"#088A08\")\n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_ylabel(\"TVD (m)\")\n",
    "    ax1.tick_params(axis='x', colors=\"#088A08\")\n",
    "    ax1.spines[\"top\"].set_edgecolor(\"#088A08\")\n",
    "    ax1.title.set_color('#088A08')\n",
    "    ax1.set_xticks([0, 75, 150])\n",
    "    left_col_value = 0\n",
    "    right_col_value = 150\n",
    "    span = abs(left_col_value - right_col_value)\n",
    "    cmap = plt.get_cmap('hot_r')\n",
    "    color_index = np.arange(left_col_value, right_col_value, span / 100)\n",
    "    for index in sorted(color_index):\n",
    "        index_value = (index - left_col_value)/span\n",
    "        color = cmap(index_value) \n",
    "    ax12.plot(well[\"CGR\"], well['Depth'], color = \"#FF0000\", linewidth = 0.5)\n",
    "    ax12.set_xlabel('GR (GAPI)')\n",
    "    ax12.xaxis.label.set_color(\"#FF0000\")\n",
    "    ax12.set_xlim(0, 150)\n",
    "    ax12.tick_params(axis='x', colors=\"#FF0000\")\n",
    "    ax12.spines[\"top\"].set_position((\"axes\", 1.075))\n",
    "    ax12.spines[\"top\"].set_visible(True)\n",
    "    ax12.spines[\"top\"].set_edgecolor(\"#FF0000\")\n",
    "    ax12.set_xticks([0, 75, 150])\n",
    "    ax2.plot(well[\"LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax2.set_xlabel(\"GML\")\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.xaxis.label.set_color(\"black\")\n",
    "    ax2.tick_params(axis='x', colors=\"black\")\n",
    "    ax2.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax2.fill_betweenx(well['Depth'], 0, well['LITHOLOGY'], where=(well['LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax2.set_xticks([])\n",
    "    ax3.plot(well[\"val LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax3.set_xlabel(\"S-GML\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.xaxis.label.set_color(\"black\")\n",
    "    ax3.tick_params(axis='x', colors=\"black\")\n",
    "    ax3.spines[\"top\"].set_edgecolor(\"black\")\n",
    "\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax3.fill_betweenx(well['Depth'], 0, well['val LITHOLOGY'], where=(well['val LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax3.set_xticks([])\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.set_ylim(bottom_depth, top_depth)\n",
    "        ax.grid(which='major', color='lightgrey', linestyle='-')\n",
    "        ax.xaxis.set_ticks_position(\"top\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "        ax.spines[\"top\"].set_position((\"axes\", 1.01))\n",
    "    for ax in [ax1]:\n",
    "        for depth, colour in zip(formations.values(), zone_colours):\n",
    "            ax.axhspan(depth[0], depth[1], color=colour, alpha=0.5)\n",
    "    for ax in [ ax2, ax3]:\n",
    "        plt.setp(ax.get_yticklabels(), visible = False)\n",
    "    for label, formation_mid in zip(formations_dict.keys(),\n",
    "                                    formation_midpoints):\n",
    "        ax1.text(5, formation_mid, label, rotation=0,\n",
    "                verticalalignment='center', fontweight='bold',\n",
    "                fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace = 0.22)\n",
    "    fig.savefig(\"total.tiff\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y3wo0krUzUPB"
   },
   "outputs": [],
   "source": [
    "multi_window = WindowGenerator(input_width=8,\n",
    "                               label_width=1,\n",
    "                               shift=1,\n",
    "                               train_df = test,\n",
    "                               test_df = test,\n",
    "                               val_df = test,\n",
    "                               label_columns=['CGR', 'SGR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DwmyS1gGzUV4"
   },
   "outputs": [],
   "source": [
    "facies_window = WindowGenerator(input_width=8,\n",
    "                               label_width=1,\n",
    "                               shift=1,\n",
    "                                train_df = test,\n",
    "                               test_df = test,\n",
    "                               val_df = test,\n",
    "                               label_columns=['Facies'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facies_window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nkbFOXpWswMT"
   },
   "outputs": [],
   "source": [
    "preds = list()\n",
    "depth = list()\n",
    "\n",
    "for idx, (inp, tar) in enumerate(multi_window.test):\n",
    "  out = multi_lstm_model.predict(inp, verbose = 0)\n",
    "  out = np.squeeze(out)\n",
    "  preds.extend(out)\n",
    "  depth.extend(inp[:, 0, 0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "egOvb3SYxcSU",
    "outputId": "4642cf5c-9b61-4ed2-a322-2e4c98b7464d"
   },
   "outputs": [],
   "source": [
    "preds = np.array(preds)\n",
    "preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vKNPOfdNzGpp"
   },
   "outputs": [],
   "source": [
    "pred_df = data.copy(deep = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yT8G51Er1MuC"
   },
   "outputs": [],
   "source": [
    "pred_df = pred_df.iloc[:-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X6wIshlW4j6C",
    "outputId": "d1a3bd0e-10dc-4483-d579-aa072c3846e7"
   },
   "outputs": [],
   "source": [
    "pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KofoI6S4MXb",
    "outputId": "fa2bea22-32da-41ec-f422-e6987312f2f0"
   },
   "outputs": [],
   "source": [
    "idx = pred_df[pred_df.Depth > 2779.9284].index.to_numpy()\n",
    "len(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "zt0-R-xb5qkQ",
    "outputId": "0d8ab85c-29ce-4c3f-f407-448167af5a53"
   },
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "EB4J7mu52JJ-",
    "outputId": "a42312ba-aaf9-4680-86da-2a1a4f68c0c9"
   },
   "outputs": [],
   "source": [
    "pred_df[pred_df.Depth > 2779.9284].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df['LITHOLOGY'] = np.round(pred_df['LITHOLOGY'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i48fz3Yh8x5h",
    "outputId": "d10f8f32-d53d-496c-9dc9-64d31d3b2a03"
   },
   "outputs": [],
   "source": [
    "pred_df['LITHOLOGY'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U31_qv-Df7-a",
    "outputId": "8d5a1ecd-7355-4158-bae0-1eeac88feb38"
   },
   "outputs": [],
   "source": [
    "data.shape, pred_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ml01MaXlffEP",
    "outputId": "ef1bfdfa-e759-4a25-c91a-a842f2d83974"
   },
   "outputs": [],
   "source": [
    "pred_df.rename(columns={'LITHOLOGY':'val LITHOLOGY'}, inplace=True)\n",
    "pred_df.rename(columns={'CGR':'val CGR'}, inplace=True)\n",
    "pred_df.rename(columns={'SGR':'val SGR'}, inplace=True)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "Ja3jmTOGgaqr",
    "outputId": "b46211fc-dfad-4f3f-d1ce-fcf66a13739b"
   },
   "outputs": [],
   "source": [
    "df = data.merge(pred_df, on='Depth', suffixes = (None,'_1'))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(df).to_csv('dfn.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = 'dfn.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "6g15UQVe5_Rb",
    "outputId": "44590c40-c4fc-43ee-9168-2215d7d5362a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeplot(df, 2350, 3398, formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3UCPGFmSm-3R"
   },
   "outputs": [],
   "source": [
    "formations_dict= {}\n",
    "with open('Formation11_h.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict['Sarvak'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)\n",
    "formation_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_colours = [\n",
    "       '#D8D8D8','#585858','#F7FE2E','#A9E2F3', '#00FFFF']\n",
    "def makeplot(well, top_depth, bottom_depth, formations):\n",
    "    fig, ax = plt.subplots(figsize=(3.8, 8))\n",
    "    ax1 = plt.subplot2grid((1, 3), (0, 0), rowspan=1, colspan = 1)\n",
    "    ax12 = ax1.twiny()\n",
    "    ax2 = plt.subplot2grid((1, 3), (0, 1), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax3 = plt.subplot2grid((1, 3), (0, 2), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax10 = ax1.twiny()\n",
    "    ax10.xaxis.set_visible(False)\n",
    "    ax1.plot(well[\"val CGR\"], well['Depth'], color = \"#088A08\", linewidth = 0.5)\n",
    "    ax1.set_xlabel(\"S-GR (GAPI)\")\n",
    "    ax1.xaxis.label.set_color(\"#088A08\")\n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_ylabel(\"TVD (m)\")\n",
    "    ax1.tick_params(axis='x', colors=\"#088A08\")\n",
    "    ax1.spines[\"top\"].set_edgecolor(\"#088A08\")\n",
    "    ax1.title.set_color('#088A08')\n",
    "    ax1.set_xticks([0, 75, 150])\n",
    "    left_col_value = 0\n",
    "    right_col_value = 150\n",
    "    span = abs(left_col_value - right_col_value)\n",
    "    cmap = plt.get_cmap('hot_r')\n",
    "    color_index = np.arange(left_col_value, right_col_value, span / 100)\n",
    "    for index in sorted(color_index):\n",
    "        index_value = (index - left_col_value)/span\n",
    "        color = cmap(index_value) \n",
    "    ax12.plot(well[\"CGR\"], well['Depth'], color = \"#FF0000\", linewidth = 0.5)\n",
    "    ax12.set_xlabel('GR (GAPI)')\n",
    "    ax12.xaxis.label.set_color(\"#FF0000\")\n",
    "    ax12.set_xlim(0, 150)\n",
    "    ax12.tick_params(axis='x', colors=\"#FF0000\")\n",
    "    ax12.spines[\"top\"].set_position((\"axes\", 1.075))\n",
    "    ax12.spines[\"top\"].set_visible(True)\n",
    "    ax12.spines[\"top\"].set_edgecolor(\"#FF0000\")\n",
    "    ax12.set_xticks([0, 75, 150])\n",
    "    ax2.plot(well[\"LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax2.set_xlabel(\"GML\")\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.xaxis.label.set_color(\"black\")\n",
    "    ax2.tick_params(axis='x', colors=\"black\")\n",
    "    ax2.spines[\"top\"].set_edgecolor(\"black\")\n",
    "\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax2.fill_betweenx(well['Depth'], 0, well['LITHOLOGY'], where=(well['LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax2.set_xticks([])\n",
    "    ax3.plot(well[\"val LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax3.set_xlabel(\"S-GML\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.xaxis.label.set_color(\"black\")\n",
    "    ax3.tick_params(axis='x', colors=\"black\")\n",
    "    ax3.spines[\"top\"].set_edgecolor(\"black\")\n",
    "\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax3.fill_betweenx(well['Depth'], 0, well['val LITHOLOGY'], where=(well['val LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax3.set_xticks([])\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.set_ylim(bottom_depth, top_depth)\n",
    "        ax.grid(which='major', color='lightgrey', linestyle='-')\n",
    "        ax.xaxis.set_ticks_position(\"top\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "        ax.spines[\"top\"].set_position((\"axes\", 1.01))\n",
    "    for ax in [ax1]:\n",
    "        for depth, colour in zip(formations.values(), zone_colours):\n",
    "            ax.axhspan(depth[0], depth[1], color=colour, alpha=0.5)\n",
    "    for ax in [ ax2, ax3]:\n",
    "        plt.setp(ax.get_yticklabels(), visible = False)\n",
    "    for label, formation_mid in zip(formations_dict.keys(),\n",
    "                                    formation_midpoints):\n",
    "        ax1.text(5, formation_mid, label, rotation=0,\n",
    "                verticalalignment='center', fontweight='bold',\n",
    "                fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace = 0.22)\n",
    "    fig.savefig(\"2800-3000.tiff\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations = {\"Sarvak\": [2800.0, 3000.0],\n",
    "              \"Gurpi\":[2350.618, 2659.99], \n",
    "              \"Ilam\": [2660.142, 2757.938],\n",
    "              \"Lafan\": [2758.135, 2768.956]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sarvak.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]\n",
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeplot(df, 2800, 3000,formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}\n",
    "with open('Formation12_h.csv', 'r') as file:\n",
    "    next(file) \n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict['Sarvak'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)  \n",
    "formation_midpoints\n",
    "zone_colours = ['#A9E2F3',\n",
    "       '#585858','#F7FE2E','#D8D8D8', '#00FFFF']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_colours = [\n",
    "       '#D8D8D8','#585858','#F7FE2E','#A9E2F3', '#00FFFF']\n",
    "def makeplot(well, top_depth, bottom_depth, formations):\n",
    "    fig, ax = plt.subplots(figsize=(3.8, 8))\n",
    "    ax1 = plt.subplot2grid((1, 3), (0, 0), rowspan=1, colspan = 1)\n",
    "    ax12 = ax1.twiny()\n",
    "    ax2 = plt.subplot2grid((1, 3), (0, 1), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax3 = plt.subplot2grid((1, 3), (0, 2), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax10 = ax1.twiny()\n",
    "    ax10.xaxis.set_visible(False)\n",
    "    ax1.plot(well[\"val CGR\"], well['Depth'], color = \"#088A08\", linewidth = 0.5)\n",
    "    ax1.set_xlabel(\"S-GR (GAPI)\")\n",
    "    ax1.xaxis.label.set_color(\"#088A08\")\n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_ylabel(\"TVD (m)\")\n",
    "    ax1.tick_params(axis='x', colors=\"#088A08\")\n",
    "    ax1.spines[\"top\"].set_edgecolor(\"#088A08\")\n",
    "    ax1.title.set_color('#088A08')\n",
    "    ax1.set_xticks([0, 75, 150])\n",
    "    left_col_value = 0\n",
    "    right_col_value = 150\n",
    "    span = abs(left_col_value - right_col_value)\n",
    "    cmap = plt.get_cmap('hot_r')\n",
    "    color_index = np.arange(left_col_value, right_col_value, span / 100)\n",
    "    for index in sorted(color_index):\n",
    "        index_value = (index - left_col_value)/span\n",
    "        color = cmap(index_value)\n",
    "    ax12.plot(well[\"CGR\"], well['Depth'], color = \"#FF0000\", linewidth = 0.5)\n",
    "    ax12.set_xlabel('GR (GAPI)')\n",
    "    ax12.xaxis.label.set_color(\"#FF0000\")\n",
    "    ax12.set_xlim(0, 150)\n",
    "    ax12.tick_params(axis='x', colors=\"#FF0000\")\n",
    "    ax12.spines[\"top\"].set_position((\"axes\", 1.075))\n",
    "    ax12.spines[\"top\"].set_visible(True)\n",
    "    ax12.spines[\"top\"].set_edgecolor(\"#FF0000\")\n",
    "    ax12.set_xticks([0, 75, 150])\n",
    "    ax2.plot(well[\"LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax2.set_xlabel(\"GML\")\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.xaxis.label.set_color(\"black\")\n",
    "    ax2.tick_params(axis='x', colors=\"black\")\n",
    "    ax2.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax2.fill_betweenx(well['Depth'], 0, well['LITHOLOGY'], where=(well['LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax2.set_xticks([])\n",
    "    ax3.plot(well[\"val LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax3.set_xlabel(\"S-GML\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.xaxis.label.set_color(\"black\")\n",
    "    ax3.tick_params(axis='x', colors=\"black\")\n",
    "    ax3.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax3.fill_betweenx(well['Depth'], 0, well['val LITHOLOGY'], where=(well['val LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax3.set_xticks([])\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.set_ylim(bottom_depth, top_depth)\n",
    "        ax.grid(which='major', color='lightgrey', linestyle='-')\n",
    "        ax.xaxis.set_ticks_position(\"top\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "        ax.spines[\"top\"].set_position((\"axes\", 1.01))\n",
    "    for ax in [ax1]:\n",
    "        for depth, colour in zip(formations.values(), zone_colours):\n",
    "            ax.axhspan(depth[0], depth[1], color=colour, alpha=0.5)\n",
    "    for ax in [ ax2, ax3]:\n",
    "        plt.setp(ax.get_yticklabels(), visible = False)\n",
    "    for label, formation_mid in zip(formations_dict.keys(),\n",
    "                                    formation_midpoints):\n",
    "        ax1.text(5, formation_mid, label, rotation=0,\n",
    "                verticalalignment='center', fontweight='bold',\n",
    "                fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace = 0.22)\n",
    "    fig.savefig(\"3000-3200.tiff\", dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations = {\"Sarvak\": [3000.0, 3200.0],\n",
    "              \"Gurpi\":[2350.618, 2659.99], \n",
    "              \"Ilam\": [2660.142, 2757.938],\n",
    "              \"Lafan\": [2758.135, 2768.956]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sarvak_1.csv', 'r') as file:\n",
    "    next(file) #skip header row\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]\n",
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "makeplot(df, 3000, 3200,formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}\n",
    "with open('Formation13_h.csv', 'r') as file:\n",
    "    next(file)\n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict['Sarvak'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_midpoints = []\n",
    "for key, value in formations_dict.items():\n",
    "    formation_midpoints.append(value[0] + (value[1]-value[0])/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formation_midpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zone_colours = [\n",
    "       '#D8D8D8','#585858','#F7FE2E','#A9E2F3', '#00FFFF']\n",
    "def makeplot(well, top_depth, bottom_depth, formations):\n",
    "    fig, ax = plt.subplots(figsize=(3.8, 8))\n",
    "    ax1 = plt.subplot2grid((1, 3), (0, 0), rowspan=1, colspan = 1)\n",
    "    ax12 = ax1.twiny()\n",
    "    ax2 = plt.subplot2grid((1, 3), (0, 1), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax3 = plt.subplot2grid((1, 3), (0, 2), rowspan=1, colspan = 1, sharey = ax1)\n",
    "    ax10 = ax1.twiny()\n",
    "    ax10.xaxis.set_visible(False)\n",
    "    ax1.plot(well[\"val CGR\"], well['Depth'], color = \"#088A08\", linewidth = 0.5)\n",
    "    ax1.set_xlabel(\"S-GR (GAPI)\")\n",
    "    ax1.xaxis.label.set_color(\"#088A08\")\n",
    "    ax1.set_xlim(0, 150)\n",
    "    ax1.set_ylabel(\"TVD (m)\")\n",
    "    ax1.tick_params(axis='x', colors=\"#088A08\")\n",
    "    ax1.spines[\"top\"].set_edgecolor(\"#088A08\")\n",
    "    ax1.title.set_color('#088A08')\n",
    "    ax1.set_xticks([0, 75, 150])\n",
    "    left_col_value = 0\n",
    "    right_col_value = 150\n",
    "    span = abs(left_col_value - right_col_value)\n",
    "    cmap = plt.get_cmap('hot_r')\n",
    "    color_index = np.arange(left_col_value, right_col_value, span / 100)\n",
    "    for index in sorted(color_index):\n",
    "        index_value = (index - left_col_value)/span\n",
    "        color = cmap(index_value) \n",
    "    ax12.plot(well[\"CGR\"], well['Depth'], color = \"#FF0000\", linewidth = 0.5)\n",
    "    ax12.set_xlabel('GR (GAPI)')\n",
    "    ax12.xaxis.label.set_color(\"#FF0000\")\n",
    "    ax12.set_xlim(0, 150)\n",
    "    ax12.tick_params(axis='x', colors=\"#FF0000\")\n",
    "    ax12.spines[\"top\"].set_position((\"axes\", 1.075))\n",
    "    ax12.spines[\"top\"].set_visible(True)\n",
    "    ax12.spines[\"top\"].set_edgecolor(\"#FF0000\")\n",
    "    ax12.set_xticks([0, 75, 150])\n",
    "    ax2.plot(well[\"LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax2.set_xlabel(\"GML\")\n",
    "    ax2.set_xlim(0, 1)\n",
    "    ax2.xaxis.label.set_color(\"black\")\n",
    "    ax2.tick_params(axis='x', colors=\"black\")\n",
    "    ax2.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax2.fill_betweenx(well['Depth'], 0, well['LITHOLOGY'], where=(well['LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax2.set_xticks([])\n",
    "    ax3.plot(well[\"val LITHOLOGY\"], well['Depth'], color = \"black\", linewidth = 0.5)\n",
    "    ax3.set_xlabel(\"S-GML\")\n",
    "    ax3.set_xlim(0, 1)\n",
    "    ax3.xaxis.label.set_color(\"black\")\n",
    "    ax3.tick_params(axis='x', colors=\"black\")\n",
    "    ax3.spines[\"top\"].set_edgecolor(\"black\")\n",
    "    for key in lithology_numbers.keys():\n",
    "        color = lithology_numbers[key]['color']\n",
    "        hatch = lithology_numbers[key]['hatch']\n",
    "        ax3.fill_betweenx(well['Depth'], 0, well['val LITHOLOGY'], where=(well['val LITHOLOGY']==key),\n",
    "                         facecolor=color, hatch=hatch)\n",
    "    ax3.set_xticks([])\n",
    "    for ax in [ax1, ax2, ax3]:\n",
    "        ax.set_ylim(bottom_depth, top_depth)\n",
    "        ax.grid(which='major', color='lightgrey', linestyle='-')\n",
    "        ax.xaxis.set_ticks_position(\"top\")\n",
    "        ax.xaxis.set_label_position(\"top\")\n",
    "        ax.spines[\"top\"].set_position((\"axes\", 1.01))\n",
    "    for ax in [ax1]:\n",
    "        for depth, colour in zip(formations.values(), zone_colours):\n",
    "            ax.axhspan(depth[0], depth[1], color=colour, alpha=0.5)\n",
    "    for ax in [ ax2, ax3]:\n",
    "        plt.setp(ax.get_yticklabels(), visible = False)\n",
    "    for label, formation_mid in zip(formations_dict.keys(),\n",
    "                                    formation_midpoints):\n",
    "        ax1.text(5, formation_mid, label, rotation=0,\n",
    "                verticalalignment='center', fontweight='bold',\n",
    "                fontsize='large')\n",
    "    plt.tight_layout()\n",
    "    fig.subplots_adjust(wspace = 0.22)\n",
    "    fig.savefig(\"3200-3398.tiff\", dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations = {\"Sarvak\": [3200.0, 3398.0],\n",
    "              \"Gurpi\":[2350.618, 2659.99], \n",
    "              \"Ilam\": [2660.142, 2757.938],\n",
    "              \"Lafan\": [2758.135, 2768.956]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict= {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Sarvak_2.csv', 'r') as file:\n",
    "    next(file) \n",
    "    for row in csv.DictReader(file, fieldnames=['Formation', 'Top', 'Bottom']):\n",
    "        formations_dict[row['Formation']]=[float(row['Top']), float(row['Bottom'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formations_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeplot(df, 3200, 3398,formations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framerate = 4410\n",
    "play_time_seconds = 3\n",
    "t = np.linspace(0, play_time_seconds, framerate*play_time_seconds)\n",
    "audio_data = np.sin(2*np.pi*300*t) + np.sin(2*np.pi*240*t)\n",
    "Audio(audio_data, rate=framerate, autoplay=True)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
